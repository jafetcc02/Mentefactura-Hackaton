{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rgl2vX8r7e3"
      },
      "source": [
        "# Miguel Angel Paz Camacho\n",
        "\n",
        "# Hackaton Mentes Bayesianas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov8sI51Xr7e5"
      },
      "source": [
        "# 1 Modelos de Lenguaje Neuronales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "13CYpArCr7e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "from typing import Tuple\n",
        "from argparse import Namespace\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Preprosacimiento\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#PyTorch\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "#scikit-learn\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Para lectura de embedings\n",
        "\n",
        "from gensim.models import KeyedVectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0cci5ht-r7e6"
      },
      "outputs": [],
      "source": [
        "seed = 1111\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.benchmark = False # Instrucción para optimizar las convoluciones. Si esta en False permite\n",
        "#un número de inputs cambiante en lugar de uno fijo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "mYBu6hJ3r7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index([0], dtype='int64')\n",
            "['premio a la innovación a la excelencia por la asociación de comercio y contratación mundial', 'muy buena pregunta', 'sí sí quisiéramos que hubiera justicia en los relojes por favor', 'sí cómo no', 'siempre he estado del lado de las víctimas y de la justicia durante toda mi vida el caso rébsamen como seguramente otros que va a plantear la candidata del prian los he aclarado inclusive ha habido justicia lo que es deleznable realmente es lucrar con el dolor de las personas nunca seremos así', 'sí son varios temas que planteamos y además no estoy de acuerdo con lo que planteas denise porque repito se han ahorrado 24 billones de pesos si no no se pudiera haber hecho lo que se ha hecho en estos casi seis años del presidente lópez obrador', 'el gobierno de méxico tiene diversos programas en centroamérica y hay que seguir insistiendo con estados unidos porque el objetivo de los migrantes es ir a estados unidos y lo vamos a seguir insistiendo que la mejor forma de atender la migración es atender las causas apoyar al que menos tiene', 'la formación médica que fue algo que se cerró durante todo el periodo neoliberal yo hice una universidad de la salud con excelentes resultados', 'el que tiene que salir de casa es el agresor y esa ley la hicimos en la ciudad de méxico y la vamos a hacer a nivel nacional', 'durante mi gestión la fiscalía general de justicia de la ciudad de méxico que es autónoma creó la fiscalía antifeminicidios gracias a eso en la ciudad de méxico feminicidio que se comete feminicidio que es castigado es decir cero impunidad en feminicidios gracias a un procedimiento de investigación que dio excelentes resultados y es una de las propuestas que tenemos a nivel nacional', 'sí le cambiaron', 'por cierto hay que recordar que el 22 de noviembre o en noviembre del 2022 la candidata del prian dijo que los programas sociales deben ser temporales ahora se han dedicado a decir que ellos siempre estuvieron de acuerdo con los programas sociales', 'tenemos que llegar a esos jóvenes y darles la posibilidad de que estudien la preparatoria es mejor tener a los jóvenes en el aula que en la calle', 'si tiene pruebas que las presente ante el ministerio público', 'esa encuesta de coneval a que se refieren los dos candidatos la candidata y el candidato la candidata del prian y el candidato de movimiento ciudadano es una encuesta de coneval que preguntó sobre el insabi', 'nosotros hablamos de programas sociales para los adultos mayores de 65 años estamos proponiendo que todas las mujeres de 60 64 años sean reconocidas por primera vez el trabajo que hicieron en el hogar y que puedan tener un apoyo mensual', 'por eso ahora hay programas sociales que se han convertido en derechos por eso ahora hay obras estratégicas que han dado más de 500 mil empleos', 'yo prefiero que pase primero quien se quita la bolsa de tiempo', 'ésta es una gráfica de la encuesta nacional de calidad e impacto gubernamental del inegi tomada en 2015 y en 2023', 'es falso que no haya avances', 'premio a la innovación en las compras públicas por la oea el bid y la red interamericana de compras', 'esencialmente se trata de fortalecer el sistema de salud pública en la constitución está establecido en el cuarto constitucional el sistema nacional de salud pública para el bienestar que está constituido por el imss por el issste y por el imssbienestar', 'empoderar a las enfermeras que es algo fundamental que ocurre en nuestros sistemas de salud que pueden dar muchos más centros de toma de muestras y farmacias del bienestar para avanzar todavía más en la mega farmacia y distribuir medicamentos', 'vamos a hablar de la corrupción porque lo peor además de ser mentirosa pues es ser corrupta y ser mentirosa', 'sí nada más que la candidata del prian llegó por un pacto corrupto firmado en coahuila', 'cuando fui jefa de gobierno hice dos universidades públicas la rosario castellanos y la universidad de la salud y con excelentes resultados hoy 50 mil jóvenes van a la universidad gratuita porque así debe ser la educación es un derecho que antes no iban esto lo vamos a hacer a nivel nacional', 'en el caso de los tres', 'también quiero poner en contexto antes de preguntar la pregunta que en este debate se van a presentar principalmente dos proyectos el proyecto de regresar al pasado de la corrupción y el proyecto que significa avanzar con la transformación', 'un apoyo para mejora de vivienda la rehabilitación para personas con discapacidad y estamos hablando también porque hay que decir lo que no se toca muchas veces el tema de maltrato a los animales que quede en la constitución', 'cuál es la propuesta que planteamos educación inicial que no son las estancias infantiles de calderón que eran bastante corruptas', 'por primera vez en el país hay un gabinete paritario nunca antes lo había habido lo tuve también en la ciudad de méxico eso hay que llevarlo a rango de ley', 'durante el gobierno de la ciudad de méxico hubo transparencia absoluta si no no tendríamos cerca de 10 premios del bip de la oea hicimos el tianguis digital están todas las aplicaciones que ustedes pueden ver en el teléfono en la aplicación de la ciudad de méxico', 'y solamente digo que es absolutamente falso lo que plantea fue fentanilo lo que se compró durante la pandemia que es una medicina que era fundamental para poder poner los respiradores y por otro lado es falso que no haya transparencia y ahora te lo voy a demostrar', 'quiero darles una gráfica que es bastante reveladora del llamado seguro popular que se implementó durante varios años en nuestro país', 'hasta la bolsa de tiempo la candidata del prian se las quiere robar', 'sí a ver lo que yo estoy planteando no es algo que sea una propuesta mía surgió de una mesa de trabajo coordinada por diálogos por la transformación donde han participado distintas personalidades que tienen que ver con una diversidad plural no solamente vienen de morena', 'qué tal muy buenas noches', 'para la protección de niñas y niños uno de los planteamientos justamente que estamos haciendo es el fortalecimiento que estén en la escuela y que estén en la educación inicial y por eso son las becas que estamos planteando becas universales ya lo hice en la ciudad de méxico soy la única que tiene resultados de los tres que estamos aquí y lo vamos a hacer a nivel nacional', 'bajaron los feminicidios en 30 por ciento ahí están los datos', 'como presidenta vamos a seguir con la austeridad republicana', 'a', 'nosotros construimos derechos no privilegios no construimos mercancías que fue la máxima del periodo neoliberal y así vamos a seguir', 'no que conteste', 'no sé si hay un problema ahí con el reloj yo creo que valdría la pena que se revisara', 'cuando fui jefa de gobierno decreté la alerta por violencia contra las mujeres en noviembre de 2019', 'ahora cuáles son las nuestras propuestas la prevención como un tema central casa por casa escuela por escuela la atención los 365 días del año que haya médicos 24 horas del día', 'el insabi nadie lo conocía porque en realidad era un sistema de distribución de recursos hoy ya hay un sistema de seguridad pública que ofrece salud para todos aquellos que no tienen imss e issste que es el imssbienestar y ya mostré la gráfica de que tiene mucho mayor satisfacción que el anterior seguro popular', 'ahora lo más importante es que no va a disminuir la migración si no se atienden las causas y las causas de la migración son esencialmente la pobreza particularmente en centroamérica y en otros países en donde hay se produce la migración', 'sí', 'pero lo peor de todo es que falsificó invitaciones restringidas en el caso de contratos con el instituto nacional de evaluación educativa', 'sí', 'premio a la innovación en transparencia del instituto nacional de transparencia y muchos otros más', 'debe ser accesible por cierto ahí hay varias cosas que dicen que los segundos pisos no era transparente fue transparente toda la vida', 'hoy tenemos un modelo que es el humanismo mexicano que ha demostrado resultados', 'quiero seguir avanzando vamos a ampliar el número de viviendas para las y los jóvenes vamos a cambiar la ley del infonavit y la constitución para que sea el propio infonavit quien construya las viviendas estamos hablando de alrededor de un millón de viviendas no las que se construyeron en el pasado sino realmente viviendas que estén cerca de los lugares de trabajo', 'aquí hay un caso de mentira de la candidata en donde muestra que iba a donar su departamento al colegio salesiano no solamente no lo vendió no solamente no lo donó sino que lo vendió a la sobrina de felipe calderón por millones de pesos', 'por qué no hablamos de grupos vulnerables porque del tema de mujeres hablamos ya he hablado de que hay resultados y tenemos otros programas', 'esto nos permitió que tuviéramos cero observaciones de la auditoría superior de la federación en el 2022 y cero pesos por comprobar', 'y por otro lado la agencia nacional anticorrupción que no es sólo una idea mía sino producto de un proyecto de nación que hemos elaborado con distintas personalidades que ustedes conocen las coordina el doctor juan ramón de la fuente se consultó a una cantidad de expertos y de ciudadanos de manera plural y determinaron hacer la agencia nacional anticorrupción para poder seguir disminuyendo la impunidad', 'dos dar beca a todos los estudiantes de preescolar primaria y secundaria que van a escuela pública lo hice en la ciudad de méxico con excelentes resultados', 'lo primero que tiene que haber es austeridad republicana porque no puede haber lujos en los gobiernos ni tampoco tirar el combate a la corrupción y lo segundo son distintas instituciones que hemos planteado que no representan más gasto como la agencia nacional anticorrupción que nos va a permitir juntar información y acabar con la impunidad', 'y ésa es la propuesta esencial que estamos planteando y es el debate justamente con estados unidos que lo que se dedica hoy al armamentismo un porcentaje de eso se dedique para la ayuda a los países y disminuya la migración eso es lo más humano que se puede hacer', 'estamos planteando verdaderas pensiones que se recuperen las pensiones para los trabajadores y echemos atrás las leyes del 97 y del 2007 de los partidos que defienden a la candidata del prian', 'no hubo ninguna otra entidad en la república que tuviera esta calificación y después voy a hablar más adelante de lo que hicimos en la ciudad', 'hoy quiero hacer un llamado a todos y a todas a empresarios a clases medias a trabajadores a hombres a mujeres a todos y a todas a que sean parte de este proyecto', 'pero miren vamos a ir por los resultados porque de los tres que estamos aquí la única que tiene resultados en transparencia y en combate a la corrupción soy yo cuando fui jefa de gobierno', 'sí exactamente', 'sí vamos a plantear dos temas', 'ahora sí vamos a responder la pregunta', 'por supuesto que tienen que tener una atención', 'estamos planteando también como programa la universalidad de la beca para los niños y niñas más becas para jóvenes de preparatoria más universidades y estamos planteando por supuesto aumento al salario mínimo que quede establecido en la constitución que el aumento al salario mínimo siempre estará por encima de la inflación cosa que no se hizo en todos los gobiernos del prian', 'una persona en tijuana me dijo estoy con el presidente lópez obrador porque por primera vez nos volteó a ver', 'sí recientemente se puso en marcha la nueva escuela mexicana con los nuevos libros de texto', 'se ha avanzado bastante y además con la beca que dio el presidente de la república pero todavía hay 15 millones de jóvenes de 15 a 18 años que no tienen acceso a la preparatoria o que la dejaron', 'aquí están las pruebas se las voy a dejar a los conductores que son periodistas', 'vamos a hablar de los contratos de la candidata del prian número uno residencial mariano escobedo dio el permiso cuando fue jefa delegacional y después tuvo un contrato con esa misma empresa por 70 millones de pesos', 'fortalecer la preparatoria o la educación media superior', 'antes de tomar la pregunta quisiera nada más decir que aquí la candidata del prian pues la verdad es que dice muchas mentiras porque no sé con cuánto dinero va a poder pagar los medicamentos en instituciones privadas porque además como ya lo dijimos eso genera enorme corrupción', 'nuestro proyecto es fortalecerlo desde la prevención hasta la tensión más compleja de cualquier enfermedad de la salud y los medicamentos gratuitos tenemos el presupuesto para poderlo hacer', 'siempre hemos defendido la educación y la salud pública en la ciudad de méxico le di becas a todos los niños y niñas que van a escuela pública vamos a hacer ahora un programa para los niños de la primera infancia', 'ahora voy a la ivermectina', 'vamos a hablar de los programas sociales que nosotros los consideramos como derechos', 'lo que es un hecho es que hoy tenemos un presidente honesto nunca podrán decir lo mismo de los presidentes del prian que representa la candidata', 'para gobernar con honestidad hay que ser honesta', 'a ver les voy a decir los premios los reconocimientos que tuve como jefa de gobierno a la transparencia en las compras públicas en las licitaciones y también en el portal de programas sociales', 'a está bien', 'sí', 'premio eduardo campos para el uso de datos y servicios del banco interamericano de desarrollo', 'sí por supuesto que hay que ir invirtiendo cada vez más', 'la autonomía económica y por eso el apoyo de 60 a 64 años y seguir apoyando a las mujeres para que lo tengan y puedan permitirse la posibilidad de desarrollar la autonomía política que es fundamental en las decisiones y también los derechos de las mujeres en términos físicos', 'bueno los índices de feminicidio a nivel nacional han bajado más de 40 por ciento', 'en el caso del seguro popular solamente el 47 por ciento se sentía satisfecho', 'lo primero segunda mentira de la candidata del prian solamente hay que ver sus declaraciones patrimoniales en el senado de la república que son totalmente contradictorias inclusive una de sus empresas no está mencionada en las declaraciones patrimoniales aun cuando es parte del registro público de comercio así las mentiras del prian', 'siempre se plantea que la mujer que está vulnerada hay que sacarla a un refugio siempre me plantee por qué la mujer tiene que ir a un refugio no', 'antes que nada quisiera felicitar al cuerpo diplomático de méxico en ecuador que acaba de regresar felicitarlo por su valentía', 'la privatización de los servicios de salud ya se probó en el pasado en méxico ya se ha probado en muchos lugares del mundo y no solo no ha funcionado sino que se ha convertido en centro de la corrupción que fue parte de lo que pasó con el seguro popular', 'ahora en este gobierno ya no hay colusión entre el poder económico y el poder político como jefa de gobierno ahorré 100 mil millones de pesos del último gobierno del prd en corrupción', 'bueno para este tema nosotros hicimos varias leyes en la ciudad de méxico pero uno muy importante es empoderar a las mujeres', 'en cuanto a las mujeres en la ciudad de méxico es de las pocas entidades que se ha aprobado la ley vicaria que justamente tiene que ver con estos temas', 'vamos a hablar en este caso también si me lo permiten porque no solamente estamos hablando de la comunidad trans sino de todo lo que tiene que ver con discriminación', 'sí ya inicia ahora la bolsa de tiempo verdad', 'el primero fíjense que se cerraron durante todo el periodo neoliberal del prian que representa la candidata del prian los acceso a estudiar medicina entonces no hay suficientes médicos especialistas en el país', 'y vamos a poner algo que es fundamental yo vivo en un departamento rentado ella vive en una casa del cártel inmobiliario', 'es muy interesante este modelo porque no es un modelo que esté basado en la memorización y en que independientemente del lugar donde se viva es el mismo tipo de educación sino que está basado en la participación de los niños', 'y hoy méxico está floreciendo 32 de crecimiento económico el mayor nivel de empleo formal en la historia de méxico el mayor incremento salarial al salario mínimo y el mayor salario medio que haya existido en los últimos años en la historia de méxico las mayores reservas del banco de méxico', 'sí voy a plantear dos temas', 'es muy sencillo centros de salud y formación de médicos y de enfermeras ya lo hicimos en la ciudad de méxico', 'fíjense esto eh fuimos la entidad federativa con la mejor evaluación de acciones de transparencia durante el covid 19 y saben por quién por transparencia mexicana justamente una de las organizaciones que no es precisamente fan de la cuarta transformación', 'sí más que responderle plantear lo siguiente', 'y tener un mejor modelo de referencia y contra referencia fortalecer la atención a la salud primaria', 'el pueblo de méxico quiere que sigamos avanzando con la transformación', 'e igual estamos planteando la recuperación salarial de los maestros de las maestras de la guardia nacional la nueva institución de seguridad pública en nuestro país de policías', 'y por otro lado más universidades', 'sí eso ya lo decidió la suprema corte de justicia de la nación en nuestro país y lo que hay que hablar es de los derechos en términos amplios de las mujeres', 'buenas noches a todos', 'ahora ya está funcionando y vamos a hacerlo funcionar mejor', 'lo hicimos en la ciudad de méxico estamos totalmente en contra de cualquier forma de discriminación inclusive hay que llevarlo al código penal', 'estamos planteando también la recuperación de los salarios para aquellos que trabajan en el instituto mexicano del seguro social', 'los gobiernos del pasado se dedicaron a discriminar por primera vez hay un gobierno que atiende a los que menos tienen', 'a ver estamos hablando del crimen organizado no es un tema distinto si quieren lo tocamos en segundo debate que vamos a hablar de seguridad', 'cómo creerle a una mentirosa', 'hicimos una serie de acciones que nos permitieron disminuir la violencia para disminuir las violencias tiene que haber dos ejes fundamentales la atención a las causas y la cero impunidad', 'campeones en rendición de cuentas en transparencia por la asociación de contrataciones abiertas internacional integrada por 200 miembros', 'sí son muchas cosas por aclarar', 'vamos a hablar de otros temas también', 'voy a ser la primera mujer presidenta de méxico', 'la no espero', 'hay dos temas fundamentales que estamos planteando uno ya lo hice en la ciudad con resultados es digitalizar a partir de la digitalización cree la bip en la ciudad de méxico a partir de la digitalización no solamente puede aumentar la recaudación sino que también disminuye la corrupción de distinto tipo', 'el candidato del pan en la ciudad de méxico es justamente parte de este cártel inmobiliario que protege la candidato del prian', 'en el caso del imss bienestar el 579 por ciento se siente satisfecho', 'es parte de nuestras propuestas que tenemos en esta área de combate a la corrupción y gobierno honesto', 'sí']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_4628\\541386454.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  Data_pd = pd.read_csv('claudia.csv', header=None, sep=\"\\n\\n\")\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Data_pd = pd.read_csv('claudia.csv', header=None, sep=\"\\n\\n\")\n",
        "print(Data_pd.columns)\n",
        "#print(X_train.columns)\n",
        "\n",
        "Tweets = Data_pd[0].tolist()\n",
        "#print(Tweets)\n",
        "#Tweets = Data_pd[\"tweetText\"].tolist()\n",
        "\n",
        "X_train, X_val = train_test_split(Tweets, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train)\n",
        "#X_val = pd.read_csv('mex20_val.txt', sep='\\r\\n', engine='python', header=None).loc[:,0].values.tolist()\n",
        "#print(X_val)\n",
        "#embeddings_model = KeyedVectors.load_word2vec_format('word2vec_col.txt', binary=False)\n",
        "#print(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te3RwtpBr7e6"
      },
      "source": [
        "## Trabajo Practica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAKxuVcyr7e6"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1MyIG4Yur7e7"
      },
      "outputs": [],
      "source": [
        "args = Namespace()\n",
        "args.N = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "FJTisS6Lr7e7"
      },
      "outputs": [],
      "source": [
        "class NgramData():\n",
        "\n",
        "    def __init__(self, N: int, vocab_max: int=5000, tokenizer=None, embeddings_model=None):\n",
        "        self.tokenizer = tokenizer if tokenizer else self.default_tokenizer\n",
        "        self.punct = set(['.', ',', ';', ':', '-', '^', '»', '!', '¡', '¿', '?', '\"', '\\'', '...', '<url>', '*', '@usuario'])\n",
        "        self.N = N\n",
        "        self.vocab_max = vocab_max\n",
        "        self.UNK = \"<unk>\"\n",
        "        self.SOS = '<s>'\n",
        "        self.EOS = '</s>'\n",
        "        self.embeddings_model = embeddings_model\n",
        "\n",
        "    def get_vocab_size(self) -> int:\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def default_tokenizer(self, doc:str) -> list:\n",
        "        return doc.split(\" \")\n",
        "\n",
        "    def remove_word(self, word: str) -> bool:\n",
        "        word = word.lower()\n",
        "        is_punct = True if word in self.punct else False\n",
        "        is_digit = word.isnumeric()\n",
        "        return is_punct or is_digit\n",
        "\n",
        "    def get_vocab(self, corpus: list) -> set:\n",
        "        freq_dist = FreqDist([w.lower() for sentence in corpus\\\n",
        "                                        for w in self.tokenizer(sentence)\\\n",
        "                                        if not self.remove_word(w)])\n",
        "\n",
        "        sorted_words = self.sortFreqDict(freq_dist)[:self.vocab_max-3] #Incluimos al vocabulario las palabras \"<unk>\" '<s>' '</s>'\n",
        "        return set(sorted_words)\n",
        "\n",
        "    def sortFreqDict(self, freq_dist) -> list:\n",
        "        freq_dict = dict(freq_dist)\n",
        "        return sorted(freq_dict, key=freq_dict.get, reverse=True)\n",
        "\n",
        "    def fit(self, corpus: list) -> None:\n",
        "        self.vocab = self.get_vocab(corpus)\n",
        "        self.vocab.add(self.UNK)\n",
        "        self.vocab.add(self.SOS)\n",
        "        self.vocab.add(self.EOS)\n",
        "\n",
        "        self.w2id = {}\n",
        "        self.id2w = {}\n",
        "\n",
        "        if self.embeddings_model is not None:\n",
        "            self.embeddings_matrix = np.empty([len(self.vocab), self.embeddings_model.vector_size])\n",
        "\n",
        "        id = 0\n",
        "        for doc in corpus:\n",
        "            for word in self.tokenizer(doc):\n",
        "                word_ = word.lower()\n",
        "                if word_ in self.vocab and not word_ in self.w2id:\n",
        "                    self.w2id[word_] = id\n",
        "                    self.id2w[id] = word_\n",
        "\n",
        "                    if self.embeddings_model is not None:\n",
        "                        if word_ in self.embeddings_model:\n",
        "                            self.embeddings_matrix[id] = self.embeddings_model[word_]\n",
        "                        else:\n",
        "                            self.embeddings_matrix[id] = np.random.rand(self.embeddings_model.vector_size)\n",
        "\n",
        "                    id +=1\n",
        "\n",
        "\n",
        "        self.w2id.update(\n",
        "            {\n",
        "                self.UNK: id,\n",
        "                self.SOS: id+1,\n",
        "                self.EOS: id+2\n",
        "            }\n",
        "        )\n",
        "        self.id2w.update(\n",
        "            {\n",
        "                id: self.UNK,\n",
        "                id+1: self.SOS,\n",
        "                id+2: self.EOS\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def transform(self, corpus: list) -> Tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "        X_ngrams = []\n",
        "        y = []\n",
        "\n",
        "        for doc in corpus:\n",
        "            doc_ngram = self.get_ngram_doc(doc)\n",
        "            for words_window in doc_ngram:\n",
        "                words_window_ids = [self.w2id[w] for w in words_window]\n",
        "                X_ngrams.append(list(words_window_ids[:-1]))\n",
        "                y.append(words_window_ids[-1])\n",
        "\n",
        "        return np.array(X_ngrams), np.array(y)\n",
        "\n",
        "    def get_ngram_doc(self, doc: str) -> list:\n",
        "        doc_tokens = self.tokenizer(doc)\n",
        "        doc_tokens = self.replace_unk(doc_tokens)\n",
        "        doc_tokens = [w.lower() for w in doc_tokens]\n",
        "        doc_tokens = [self.SOS]*(self.N-1) + doc_tokens + [self.EOS]\n",
        "        return list(ngrams(doc_tokens, self.N))\n",
        "\n",
        "    def replace_unk(self, doc_tokens: list) -> list:\n",
        "        for i, token in enumerate(doc_tokens):\n",
        "            if token.lower() not in self.vocab:\n",
        "                doc_tokens[i] = self.UNK\n",
        "\n",
        "        return doc_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "dPk61G6Tr7e7"
      },
      "outputs": [],
      "source": [
        "tk = TweetTokenizer()\n",
        "ngram_data = NgramData(args.N, 5000, tk.tokenize)\n",
        "ngram_data.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T4Ld6OGr7e7",
        "outputId": "e8075426-dd73-44ac-a2ed-45b14396d135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 873\n"
          ]
        }
      ],
      "source": [
        "print(f'Vocab size: {ngram_data.get_vocab_size()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ND7Ttc-Ur7e8"
      },
      "outputs": [],
      "source": [
        "X_ngram_train, y_ngram_train = ngram_data.transform(X_train)\n",
        "X_ngram_val, y_ngram_val = ngram_data.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55tkHRZr7e8",
        "outputId": "b8737e3e-003e-4e78-fe6b-f7a7e4fe40d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training observations: X: (3398, 3), y: (3398,)\n",
            "Validation observations: X: (739, 3), y: (739,)\n"
          ]
        }
      ],
      "source": [
        "print(f'Training observations: X: {X_ngram_train.shape}, y: {y_ngram_train.shape}')\n",
        "print(f'Validation observations: X: {X_ngram_val.shape}, y: {y_ngram_val.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htFwmDAXr7e8",
        "outputId": "dd872f35-6ae4-4a26-91f8-7ba3caad1ab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['<s>', '<s>', '<s>'],\n",
              " ['<s>', '<s>', 'premio'],\n",
              " ['<s>', 'premio', 'a'],\n",
              " ['premio', 'a', 'la'],\n",
              " ['a', 'la', 'innovación'],\n",
              " ['la', 'innovación', 'a'],\n",
              " ['innovación', 'a', 'la'],\n",
              " ['a', 'la', 'excelencia'],\n",
              " ['la', 'excelencia', 'por'],\n",
              " ['excelencia', 'por', 'la']]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[[ngram_data.id2w[w] for w in tw] for tw in X_ngram_train[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opxE66D7r7e9",
        "outputId": "33f135ad-8513-4843-846a-c311d38cd433"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0,   1,   2, ..., 872,  15, 872])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_ngram_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtelBnyar7e9",
        "outputId": "5bde84a1-14b0-4cb0-e283-6a74eab98e10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['premio',\n",
              " 'a',\n",
              " 'la',\n",
              " 'innovación',\n",
              " 'a',\n",
              " 'la',\n",
              " 'excelencia',\n",
              " 'por',\n",
              " 'la',\n",
              " 'asociación']"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[ngram_data.id2w[w] for w in y_ngram_train[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "vjLJZzIvr7e9"
      },
      "outputs": [],
      "source": [
        "#Set batch size in args\n",
        "args.batch_size = 64\n",
        "\n",
        "#Num workers\n",
        "args.num_workers = 2\n",
        "\n",
        "#Train\n",
        "train_dataset = TensorDataset(torch.tensor(X_ngram_train, dtype=torch.int64),\n",
        "                              torch.tensor(y_ngram_train, dtype=torch.int64))\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=args.batch_size,\n",
        "                          num_workers=args.num_workers,\n",
        "                          shuffle=True)\n",
        "\n",
        "#Val\n",
        "val_dataset = TensorDataset(torch.tensor(X_ngram_val, dtype=torch.int64),\n",
        "                            torch.tensor(y_ngram_val, dtype=torch.int64))\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=args.batch_size,\n",
        "                          num_workers=args.num_workers,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgdhCbsr7e9",
        "outputId": "94b6859f-5c9d-4f1d-94be-039c58f3885a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([64, 3])\n",
            "Y shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(f'X shape: {batch[0].shape}')\n",
        "print(f'Y shape: {batch[1].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "QYJ9RQbRr7e9"
      },
      "outputs": [],
      "source": [
        "#Vocab size\n",
        "args.vocab_size = ngram_data.get_vocab_size()\n",
        "\n",
        "#Dimension of word embeddings\n",
        "args.d = 50\n",
        "\n",
        "#Dimension for hidden layer\n",
        "args.d_h = 100\n",
        "\n",
        "#Dropout\n",
        "args.dropout = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5KhjCvRAr7e9"
      },
      "outputs": [],
      "source": [
        "class NeuralLM(nn.Module):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super(NeuralLM, self).__init__()\n",
        "\n",
        "        self.window_size = args.N-1\n",
        "        self.embedding_dim = args.d\n",
        "\n",
        "        self.emb = nn.Embedding(args.vocab_size, args.d)\n",
        "        self.fc1 = nn.Linear(args.d*(args.N-1), args.d_h)\n",
        "        self.drop1 = nn.Dropout(p=args.dropout)\n",
        "        self.fc2 = nn.Linear(args.d_h, args.vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = x.view(-1, self.window_size*self.embedding_dim)\n",
        "        h = F.relu(self.fc1(x) )\n",
        "        h = self.drop1(h)\n",
        "        return self.fc2(h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "8DKlKNohr7e-"
      },
      "outputs": [],
      "source": [
        "def get_preds(raws_logits):\n",
        "    probs = F.softmax(raws_logits.detach(), dim=1)\n",
        "    y_pred = torch.argmax(probs, dim=1).cpu().numpy()\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "DL1ELMESr7e-"
      },
      "outputs": [],
      "source": [
        "def model_eval(data, model, gpu=False):\n",
        "    with torch.no_grad():\n",
        "        preds, tgts = [], []\n",
        "        for window_words, labels in data:\n",
        "            if gpu:\n",
        "                window_words = window_words.cuda()\n",
        "\n",
        "            outputs = model(window_words)\n",
        "\n",
        "            #Obtener prediccion\n",
        "            y_pred = get_preds(outputs)\n",
        "\n",
        "            tgt = labels.numpy()\n",
        "            tgts.append(tgt)\n",
        "            preds.append(y_pred)\n",
        "\n",
        "    tgts = [e for l in tgts for e in l]\n",
        "    preds = [e for l in preds for e in l]\n",
        "\n",
        "    return accuracy_score(tgts, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xlLcSgOOr7e-"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, is_best, checkpoint_path, filename=\"checkpoint.pt\"):\n",
        "    filename = os.path.join(checkpoint_path, filename)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, os.path.join(checkpoint_path, \"model_best.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0errkq7Yr7e-",
        "outputId": "ddd1fae4-5630-4196-b79d-8fd0cf266511"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Miguel\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ],
      "source": [
        "#Modelo Hyperparametros\n",
        "\n",
        "args.vocab_size = ngram_data.get_vocab_size()\n",
        "args.d = 100 #Dimension del embedding\n",
        "args.d_h = 200 #Dimension de la capa oculta\n",
        "args.dropout = 0.1\n",
        "\n",
        "#Training Hyperparametros\n",
        "args.lr = 2.3e-1\n",
        "args.num_epochs = 100\n",
        "args.patience = 20\n",
        "\n",
        "#Scheduler Hyperparametros\n",
        "args.lr_patience = 10\n",
        "args.lr_factor = 0.5\n",
        "\n",
        "#Saving directory\n",
        "args.savedir = 'model'\n",
        "os.makedirs(args.savedir, exist_ok=True)\n",
        "\n",
        "#Crear modelo\n",
        "model = NeuralLM(args)\n",
        "\n",
        "#Enviar a GPU\n",
        "args.use_gpu = torch.cuda.is_available()\n",
        "if args.use_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "#Perdida, Optimizador y Scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, \"min\",\n",
        "                patience=args.lr_patience,\n",
        "                verbose=True,\n",
        "                factor=args.lr_factor\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi1l2o_or7e-",
        "outputId": "f854a112-b17e-4c88-a5cf-50f2e7cdc6e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train acc:0.08024691358024691\n",
            "Epoch [1/100], Loss: 5.9066 - Val accuracy: 0.0758 - Epoch time: 11.24\n",
            "Train acc:0.1398533950617284\n",
            "Epoch [2/100], Loss: 5.0804 - Val accuracy: 0.0825 - Epoch time: 10.49\n",
            "Train acc:0.1724537037037037\n",
            "Epoch [3/100], Loss: 4.6572 - Val accuracy: 0.0947 - Epoch time: 9.20\n",
            "Train acc:0.22260802469135804\n",
            "Epoch [4/100], Loss: 4.2425 - Val accuracy: 0.1150 - Epoch time: 9.57\n",
            "Train acc:0.26263503086419754\n",
            "Epoch [5/100], Loss: 3.9053 - Val accuracy: 0.1367 - Epoch time: 12.04\n",
            "Train acc:0.31375385802469136\n",
            "Epoch [6/100], Loss: 3.5025 - Val accuracy: 0.1367 - Epoch time: 11.24\n",
            "Train acc:0.3505979938271605\n",
            "Epoch [7/100], Loss: 3.1467 - Val accuracy: 0.0568 - Epoch time: 9.00\n",
            "Train acc:0.40248842592592593\n",
            "Epoch [8/100], Loss: 2.9397 - Val accuracy: 0.1069 - Epoch time: 8.80\n",
            "Train acc:0.4592013888888889\n",
            "Epoch [9/100], Loss: 2.4614 - Val accuracy: 0.1434 - Epoch time: 8.42\n",
            "Train acc:0.4994212962962963\n",
            "Epoch [10/100], Loss: 2.1418 - Val accuracy: 0.1015 - Epoch time: 9.11\n",
            "Train acc:0.5698302469135802\n",
            "Epoch [11/100], Loss: 1.8423 - Val accuracy: 0.1258 - Epoch time: 8.95\n",
            "Train acc:0.6353202160493827\n",
            "Epoch [12/100], Loss: 1.5700 - Val accuracy: 0.1407 - Epoch time: 10.39\n",
            "Train acc:0.6995563271604938\n",
            "Epoch [13/100], Loss: 1.3345 - Val accuracy: 0.1015 - Epoch time: 8.96\n",
            "Train acc:0.7608024691358025\n",
            "Epoch [14/100], Loss: 1.1227 - Val accuracy: 0.1502 - Epoch time: 8.53\n",
            "Train acc:0.7948495370370371\n",
            "Epoch [15/100], Loss: 0.9461 - Val accuracy: 0.0934 - Epoch time: 8.69\n",
            "Train acc:0.80835262345679\n",
            "Epoch [16/100], Loss: 0.8974 - Val accuracy: 0.1028 - Epoch time: 9.58\n",
            "Train acc:0.8196373456790123\n",
            "Epoch [17/100], Loss: 0.8009 - Val accuracy: 0.1015 - Epoch time: 9.38\n",
            "Train acc:0.8182870370370371\n",
            "Epoch [18/100], Loss: 0.9048 - Val accuracy: 0.1380 - Epoch time: 8.43\n",
            "Train acc:0.8597608024691359\n",
            "Epoch [19/100], Loss: 0.6375 - Val accuracy: 0.1543 - Epoch time: 8.98\n",
            "Train acc:0.8666087962962963\n",
            "Epoch [20/100], Loss: 0.5798 - Val accuracy: 0.1705 - Epoch time: 9.39\n",
            "Train acc:0.8687307098765432\n",
            "Epoch [21/100], Loss: 0.5504 - Val accuracy: 0.1488 - Epoch time: 8.50\n",
            "Train acc:0.8695023148148148\n",
            "Epoch [22/100], Loss: 0.5604 - Val accuracy: 0.1691 - Epoch time: 9.00\n",
            "Train acc:0.8690200617283951\n",
            "Epoch [23/100], Loss: 0.5366 - Val accuracy: 0.1610 - Epoch time: 8.41\n",
            "Train acc:0.8735532407407407\n",
            "Epoch [24/100], Loss: 0.5145 - Val accuracy: 0.1543 - Epoch time: 8.94\n",
            "Train acc:0.8742283950617284\n",
            "Epoch [25/100], Loss: 0.4974 - Val accuracy: 0.1529 - Epoch time: 9.19\n",
            "Train acc:0.8741319444444444\n",
            "Epoch [26/100], Loss: 0.5089 - Val accuracy: 0.1475 - Epoch time: 9.50\n",
            "Train acc:0.8732638888888888\n",
            "Epoch [27/100], Loss: 0.4925 - Val accuracy: 0.1651 - Epoch time: 8.70\n",
            "Train acc:0.8787615740740741\n",
            "Epoch [28/100], Loss: 0.4693 - Val accuracy: 0.1502 - Epoch time: 9.85\n",
            "Train acc:0.8739390432098766\n",
            "Epoch [29/100], Loss: 0.4716 - Val accuracy: 0.1624 - Epoch time: 12.55\n",
            "Train acc:0.8895640432098766\n",
            "Epoch [30/100], Loss: 0.4390 - Val accuracy: 0.1610 - Epoch time: 10.22\n",
            "Train acc:0.8804012345679012\n",
            "Epoch [31/100], Loss: 0.4447 - Val accuracy: 0.1651 - Epoch time: 9.87\n",
            "Train acc:0.8810763888888888\n",
            "Epoch [32/100], Loss: 0.4212 - Val accuracy: 0.1664 - Epoch time: 11.41\n",
            "Train acc:0.8803047839506173\n",
            "Epoch [33/100], Loss: 0.4357 - Val accuracy: 0.1678 - Epoch time: 9.74\n",
            "Train acc:0.8775077160493827\n",
            "Epoch [34/100], Loss: 0.4380 - Val accuracy: 0.1691 - Epoch time: 10.06\n",
            "Train acc:0.882908950617284\n",
            "Epoch [35/100], Loss: 0.4190 - Val accuracy: 0.1597 - Epoch time: 9.82\n",
            "Train acc:0.8894675925925926\n",
            "Epoch [36/100], Loss: 0.4119 - Val accuracy: 0.1583 - Epoch time: 9.48\n",
            "Train acc:0.8768325617283951\n",
            "Epoch [37/100], Loss: 0.4162 - Val accuracy: 0.1651 - Epoch time: 8.93\n",
            "Train acc:0.8883101851851852\n",
            "Epoch [38/100], Loss: 0.3994 - Val accuracy: 0.1732 - Epoch time: 8.68\n",
            "Train acc:0.8732638888888888\n",
            "Epoch [39/100], Loss: 0.4267 - Val accuracy: 0.1732 - Epoch time: 8.88\n",
            "Train acc:0.8814621913580247\n",
            "Epoch [40/100], Loss: 0.4294 - Val accuracy: 0.1651 - Epoch time: 8.91\n",
            "Train acc:0.8883101851851852\n",
            "Epoch [41/100], Loss: 0.3946 - Val accuracy: 0.1746 - Epoch time: 8.41\n",
            "Train acc:0.8903356481481481\n",
            "Epoch [42/100], Loss: 0.3806 - Val accuracy: 0.1610 - Epoch time: 9.04\n",
            "Train acc:0.8844521604938271\n",
            "Epoch [43/100], Loss: 0.3985 - Val accuracy: 0.1637 - Epoch time: 8.53\n",
            "Train acc:0.8806905864197531\n",
            "Epoch [44/100], Loss: 0.3997 - Val accuracy: 0.1651 - Epoch time: 8.58\n",
            "Train acc:0.8923611111111112\n",
            "Epoch [45/100], Loss: 0.3865 - Val accuracy: 0.1664 - Epoch time: 8.61\n",
            "Train acc:0.8858989197530863\n",
            "Epoch [46/100], Loss: 0.3964 - Val accuracy: 0.1678 - Epoch time: 8.48\n",
            "Train acc:0.8884066358024691\n",
            "Epoch [47/100], Loss: 0.3891 - Val accuracy: 0.1678 - Epoch time: 8.76\n",
            "Train acc:0.8883101851851852\n",
            "Epoch [48/100], Loss: 0.3750 - Val accuracy: 0.1664 - Epoch time: 8.67\n",
            "Train acc:0.8872492283950618\n",
            "Epoch [49/100], Loss: 0.3995 - Val accuracy: 0.1651 - Epoch time: 8.33\n",
            "Train acc:0.8878279320987654\n",
            "Epoch [50/100], Loss: 0.3805 - Val accuracy: 0.1637 - Epoch time: 9.14\n",
            "Train acc:0.8849344135802469\n",
            "Epoch [51/100], Loss: 0.3812 - Val accuracy: 0.1651 - Epoch time: 10.66\n",
            "Train acc:0.8936149691358025\n",
            "Epoch [52/100], Loss: 0.3689 - Val accuracy: 0.1651 - Epoch time: 9.02\n",
            "Train acc:0.8876350308641975\n",
            "Epoch [53/100], Loss: 0.3742 - Val accuracy: 0.1664 - Epoch time: 9.03\n",
            "Train acc:0.8910108024691359\n",
            "Epoch [54/100], Loss: 0.3810 - Val accuracy: 0.1624 - Epoch time: 8.64\n",
            "Train acc:0.890625\n",
            "Epoch [55/100], Loss: 0.3718 - Val accuracy: 0.1678 - Epoch time: 8.50\n",
            "Train acc:0.890721450617284\n",
            "Epoch [56/100], Loss: 0.3816 - Val accuracy: 0.1664 - Epoch time: 9.37\n",
            "Train acc:0.8967978395061729\n",
            "Epoch [57/100], Loss: 0.3647 - Val accuracy: 0.1651 - Epoch time: 11.54\n",
            "Train acc:0.8938078703703703\n",
            "Epoch [58/100], Loss: 0.3622 - Val accuracy: 0.1664 - Epoch time: 11.04\n",
            "Train acc:0.8921682098765432\n",
            "Epoch [59/100], Loss: 0.3730 - Val accuracy: 0.1624 - Epoch time: 11.69\n",
            "Train acc:0.8933256172839507\n",
            "Epoch [60/100], Loss: 0.3715 - Val accuracy: 0.1637 - Epoch time: 9.11\n",
            "No improvement. Breaking out of loop.\n",
            "--- 575.1866364479065 seconds ---\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "best_metric = 0\n",
        "metric_history = []\n",
        "train_metric_history = []\n",
        "\n",
        "for epoch in range(args.num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    loss_epoch = []\n",
        "    training_metric = []\n",
        "    model.train()\n",
        "\n",
        "    for window_words, labels in train_loader:\n",
        "\n",
        "        #Si hay GPU\n",
        "        if args.use_gpu:\n",
        "            window_words = window_words.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(window_words)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_epoch.append(loss.item())\n",
        "\n",
        "        #Obtener metricas del entrenamiento\n",
        "        y_pred = get_preds(outputs)\n",
        "        tgt = labels.cpu().numpy()\n",
        "        training_metric.append(accuracy_score(tgt,y_pred))\n",
        "\n",
        "        #Backward and optmize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Get metric in training dataset\n",
        "    mean_epoch_metric = np.mean(training_metric)\n",
        "    train_metric_history.append(mean_epoch_metric)\n",
        "\n",
        "    #Get metric in validation dataset\n",
        "    model.eval()\n",
        "    tuning_metric = model_eval(val_loader, model, gpu=args.use_gpu)\n",
        "    metric_history.append(mean_epoch_metric)\n",
        "\n",
        "    #Update scheduler\n",
        "    scheduler.step(tuning_metric)\n",
        "\n",
        "    #Check for metric improvement\n",
        "    is_improvement = tuning_metric > best_metric\n",
        "    if is_improvement:\n",
        "        best_metric = tuning_metric\n",
        "        n_no_improve = 0\n",
        "    else:\n",
        "        n_no_improve +=1\n",
        "\n",
        "\n",
        "    #Save best model if metric improved\n",
        "    save_checkpoint(\n",
        "        {\n",
        "            \"epoch\": epoch +1,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "            \"best_metric\": best_metric,\n",
        "        },\n",
        "        is_improvement,\n",
        "        args.savedir,\n",
        "    )\n",
        "\n",
        "    #Early stopping\n",
        "    if n_no_improve >= args.patience:\n",
        "        print(\"No improvement. Breaking out of loop.\")\n",
        "        break\n",
        "\n",
        "    print('Train acc:{}'.format(mean_epoch_metric))\n",
        "    print('Epoch [{}/{}], Loss: {:.4f} - Val accuracy: {:.4f} - Epoch time: {:.2f}'\n",
        "          .format(epoch+1, args.num_epochs, np.mean(loss_epoch), tuning_metric, (time.time()- epoch_start_time)))\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsFsKIQmr7e_"
      },
      "source": [
        "### Generador de Texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "0aRxbj-wr7e_"
      },
      "outputs": [],
      "source": [
        "def print_closest_words(embeddings, ngram_data, word, n):\n",
        "    word_id = torch.LongTensor([ngram_data.w2id[word]]) #Obtener id de la palabra\n",
        "    word_embed = embeddings(word_id) #Obtener embedding de la palabra\n",
        "    dists = torch.norm(embeddings.weight - word_embed, dim=1).detach() #Calcula las distancias a todas las palabras\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) #Ordenar por distancia menor a mayor\n",
        "    for idx, difference in lst[1:n+1]:\n",
        "        print(ngram_data.id2w[idx], difference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGcS9_INr7e_",
        "outputId": "6aaa442e-2701-462e-e08d-7c02e763145e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Learned embeddings\n",
            "------------------------------\n",
            "impunidad 11.35109\n",
            "adelante 11.881222\n",
            "surgió 12.010161\n",
            "general 12.044753\n",
            "humano 12.278279\n",
            "pregunta 12.281989\n",
            "público 12.328854\n",
            "ofrece 12.365208\n",
            "constitución 12.402827\n",
            "nuestras 12.517025\n"
          ]
        }
      ],
      "source": [
        "#Modelo con embeddings aprendidos desde scratch\n",
        "best_model = NeuralLM(args)\n",
        "best_model.load_state_dict(torch.load('model/model_best.pt')['state_dict'])\n",
        "best_model.train(False)\n",
        "\n",
        "print(\"-\"*30)\n",
        "print(\"Learned embeddings\")\n",
        "print(\"-\"*30)\n",
        "print_closest_words(best_model.emb, ngram_data, \"prian\", 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "machine-learning",
      "language": "python",
      "name": "machine-learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
